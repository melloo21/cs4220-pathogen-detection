{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"6T_tuslc57JA"},"outputs":[],"source":["# import packages\n","import numpy as np\n","import pandas as pd\n","import timeit\n","import time\n","from sklearn import preprocessing\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pickle as pkl\n","from umap.umap_ import UMAP\n","import umap.plot"]},{"cell_type":"markdown","metadata":{"id":"FJtaUfX_57JE"},"source":["## Parsing Input Data\n","\n","First, some dataset statistics. We load our training labels (ground truth) and see how many reads a category (species) have."]},{"cell_type":"code","execution_count":3,"metadata":{"id":"H2nDX_MC57JF","outputId":"5184abfb-4fad-45ef-b37d-a121e374f81a"},"outputs":[{"data":{"text/plain":["decoy                              413476\n","burkholderia_pseudomallei            3533\n","pseudomonas_aeruginosa               3126\n","klebsiella_michiganensis             2989\n","mycobacterium_ulcerans               2910\n","klebsiella_pneumoniae                2806\n","serratia_liquefaciens                2629\n","vibrio_parahaemolyticus              2579\n","salmonella_enterica_typhimurium      2507\n","yersinia_enterocolitica              2276\n","stenotrophomonas_maltophilia         2217\n","mycobacterium_tuberculosis           2175\n","clostridioides_difficile             2007\n","acinetobacter_baumannii              1964\n","legionella_pneumophila               1753\n","listeria_monocytogenes               1479\n","staphylococcus_aureus                1384\n","staphylococcus_pseudintermedius      1328\n","corynebacterium_ulcerans             1266\n","corynebacterium_diphtheriae          1194\n","streptococcus_suis                   1092\n","neisseria_gonorrhoeae                1087\n","streptococcus_agalactiae             1060\n","streptococcus_pneumoniae             1056\n","staphylococcus_pyogenes               856\n","campylobacter_jejuni                  832\n","Name: species_name, dtype: int64"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["label_df = pd.read_csv('./training_data/train_labels.csv')\n","label_df['species_name'].value_counts()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"-0pyqyW-57JH"},"outputs":[],"source":["# snippet to load the grouth truth training labels and normalize the label predictions.\n","# your trained model will predict in this space (26 classes - pathogens and decoy)\n","\n","le = preprocessing.LabelEncoder()\n","le.fit(label_df['species_name'].unique())\n","y_index = le.transform(label_df['species_name'].values)\n","label_df['labels'] = y_index"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"yL8keUan57JL"},"outputs":[],"source":["# Load dictionary that maps k-mer to their corresponding index.\n","# A k-mer and its reverse complement are mapped to the same index.\n","\n","import json\n","\n","with open(\"./training_data/6-mers.json\", 'r') as dict_file:\n","    canonical_kmer_dict = json.load(dict_file)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# We define a utility function here that turns sequences to their 6-mer profiles.\n","\n","def sequence_to_kmer_profile(sequence : str, k : int = 6):\n","    \"\"\"\n","    Return the k-mer profile of the input sequence (string)\n","    \"\"\"\n","    res = np.zeros(len(set(canonical_kmer_dict.values())))\n","    for i in range(len(sequence) - k + 1):\n","        k_mer = sequence[i:i + k]\n","        if k_mer in canonical_kmer_dict:\n","            res[canonical_kmer_dict[k_mer]] += 1\n","        else:\n","            res[-1] += 1\n","\n","    res /= np.sum(res)\n","    return res"]},{"cell_type":"code","execution_count":23,"metadata":{"id":"0gtQxTzP57JM"},"outputs":[],"source":["import torch\n","from tqdm import tqdm\n","from torch.utils.data import Dataset, DataLoader\n","\n","class CS4220Dataset(Dataset):\n","    def __init__(self, data_file, label_df=None, k=6, samples_index=None, kmer_profile_on_the_fly=False, dtype=np.float32):\n","        \"\"\"\n","        Dataset class to load large CS4220 sequence database.\n","\n","        Args:\n","            - data_file (`str`): Can either be a *.fasta file if the input is raw reads, or *.npy file\n","                                 if the input is k-mer profile.\n","            - label_df (`pd.DataFrame` or `None`): A dataframe with \"labels\" column indicating the label\n","                                                   of the data (must match with data_file), or `None` if there is\n","                                                   no label (in the case of test sets).\n","            - k (`int`): The lengt of k-mer. We use 6 in this project.\n","            - samples_index (`List` or `None`): list of indices of data we sample from the data file. You\n","                                                can use this if the dataset is very large and can't fit in memory.\n","                                                set this to `None` if you want to use all the data.\n","            - kmer_profile_on_the_fly (`bool`): If input data_file is raw reads and this set to `True`,\n","                                                we will build k-mer profile on the fly. This is helpful if you want to\n","                                                alter the input sequences during training, or the k-mer profile can't fit in memory.\n","                                                Otherwise, we build k-mer profile in advance, which will speed up the\n","                                                training process.\n","            - dtype: type to store the k-mer profile. You may use, for example, `np.float32` for better precision,\n","                     or `np.float16` for smaller memory usage. If loaded from \".npy\" file, it is always `np.float16`.\n","        \"\"\"\n","        self.data_file = data_file\n","\n","        if \".fasta\" in data_file or \".fa\" in data_file or \".fna\" in data_file:\n","            self.is_raw_reads = True\n","        elif \".npy\" in data_file:\n","            self.is_raw_reads = False\n","        else:\n","            raise TypeError(f\"The input file must be either a fasta file containing raw reads (.fasta, .fa, .fna) or a numpy file containing k-mer profiles (.npy).\")\n","\n","\n","        self.label_df = label_df\n","        self.kmer_profile_otf = kmer_profile_on_the_fly\n","\n","        # k-mer length, set to be 6.\n","        self.k = k\n","\n","        # the samples we take from the read dataset\n","        self.samples_index = samples_index\n","\n","        self.dtype = dtype\n","\n","        # Load the data and store in self.reads and self.labels\n","        self.X = []\n","        self.Y = []\n","        self._read_labels()\n","        self._read_data()\n","\n","\n","    def _read_labels(self):\n","        \"\"\"\n","        Read the labels and record them in self.labels.\n","        \"\"\"\n","        if self.label_df is None:\n","            self.Y = None\n","        elif self.samples_index is None:\n","            # Load the whole dataset\n","            self.Y = list(self.label_df[\"labels\"])\n","        else:\n","            # Load only the data corresponding to the sampled index\n","            self.Y = list(self.label_df.iloc[self.samples_index][\"labels\"])\n","\n","\n","    def _read_data(self):\n","        if self.is_raw_reads:\n","            # Read the fasta file\n","            with open(self.data_file, 'r') as fasta_file:\n","                lines = fasta_file.readlines()\n","\n","            read_range = self.samples_index if self.samples_index is not None else range(int(len(lines) / 2))\n","            if not self.kmer_profile_otf:\n","                self.X = np.zeros(\n","                    (len(read_range), len(set(canonical_kmer_dict.values()))),\n","                    dtype=self.dtype\n","                )\n","\n","            for i, j in enumerate(tqdm(read_range, desc=f\"Parsing fasta file {self.data_file}\")):\n","                read = lines[j * 2 + 1].strip()\n","                if self.kmer_profile_otf:\n","                    # If chose to do k-mer profiling on the fly, simply store the reads\n","                    self.X.append(read)\n","                else:\n","                    # Otherwise, do k-mer profiling during training/testing, cost more time during training/testing\n","                    self.X[i, :] = sequence_to_kmer_profile(read, self.k)\n","        else:\n","            # Read the .npy file, and load the numpy matrix\n","            # Each row corresponds to a read, and each column corresponds to a k-mer (see training_data/6-mers.txt).\n","            self.X = np.load(self.data_file)\n","            if self.samples_index is not None:\n","                self.X = self.X[self.samples_index, :]\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"\n","        If you are using pytorch, this function helps taking data points during each epoch\n","        of your training.\n","        \"\"\"\n","        x = self.X[idx]\n","        if self.kmer_profile_otf:\n","            read_tensor = torch.tensor(sequence_to_kmer_profile(x, self.k), dtype=self.dtype)\n","        else:\n","            read_tensor = torch.tensor(x)\n","\n","        label = self.Y[idx] if self.Y is not None else None\n","        return read_tensor, label\n","\n","\n","# Example usage\n","#input_file_path = './training_data/train_raw_reads.fasta'\n","input_file_path = './training_data/train_6mers.npy'\n","\n","sampled_dataset = CS4220Dataset(input_file_path, label_df, samples_index=None)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["def create_decoy_sample(dataset, label_df, num_sample=10000, patient_num=10):\n","    sampled_decoy_idx = label_df[label_df['species_name'] == 'decoy'].sample(num_sample).index.values.tolist()\n","    sampled_data = dataset.X[sampled_decoy_idx]\n","    np.save(f'test_data/patient{patient_num}_6mers.npy', sampled_data)\n","    with open(f'test_data/patient{patient_num}_labels.csv', 'w') as f:\n","        f.write(\"labels\\n\")\n","        f.write(\"decoy\\n\")"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[],"source":["create_decoy_sample(sampled_dataset, label_df)"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"data":{"text/plain":["(10000, 2081)"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["patient_id = 10\n","with open('test_data/patient{}_6mers.npy'.format(patient_id), 'rb') as read_file:\n","    df_test = np.load(read_file)\n","df_test.shape"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"cs4220p2","language":"python","name":"cs4220p2"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
